{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  DataBase contruction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import os\n",
    "import glob\n",
    "from pandas.core.nanops import nanall\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import tree\n",
    "from XGBoost_Model import *\n",
    "import sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# reading all the data files\n",
    "data_clinical_patient = pd.read_csv('pan_origimed_2020/data_clinical_patient.txt', sep=\"\\t\")\n",
    "data_clinical_sample = pd.read_csv('pan_origimed_2020/data_clinical_sample.txt', sep=\"\\t\")\n",
    "data_cna_log2 = pd.read_csv('pan_origimed_2020/data_cna_log2.txt', sep=\"\\t\")\n",
    "data_cna = pd.read_csv('pan_origimed_2020/data_cna.txt', sep=\"\\t\")\n",
    "data_mutations = pd.read_csv('pan_origimed_2020/data_mutations.txt', sep=\"\\t\", header=2, dtype={\"Exon_Number\": \"string\"})\n",
    "data_sv = pd.read_csv('pan_origimed_2020/data_sv.txt', sep=\"\\t\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# removing bad rows\n",
    "data_clinical_sample = data_clinical_sample[4:]\n",
    "data_clinical_patient = data_clinical_patient[4:]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_clinical_patient = data_clinical_patient.rename(columns={'#Patient Identifier': 'PATIENT_ID'})"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_clinical_patient.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# matching the sample id to match other tables\n",
    "data_clinical_patient[\"SAMPLE_ID\"] = data_clinical_patient[\"PATIENT_ID\"].apply(lambda x: \"P-\" + x[7:])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# make all sample id header name the same - \"SAMPLE_ID\"\n",
    "data_clinical_sample.rename(columns={\"Sample Identifier\": 'SAMPLE_ID'}, inplace=True)\n",
    "data_mutations.rename(columns={\"Tumor_Sample_Barcode\": 'SAMPLE_ID'}, inplace=True)\n",
    "data_sv.rename(columns={\"Sample_Id\": 'SAMPLE_ID'}, inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# merge everything\n",
    "merged_clinical_data = data_clinical_patient.merge(data_clinical_sample, on=\"SAMPLE_ID\", how='outer')\n",
    "merged_mutations_data = merged_clinical_data.merge(data_mutations, on=\"SAMPLE_ID\", how='outer')\n",
    "merged_all_data = merged_mutations_data.merge(data_sv, on=\"SAMPLE_ID\", how='outer')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "merged_all_data[\"SNP_event\"] = merged_all_data[\"Reference_Allele\"].fillna(\"\").astype(str) + \">\" + merged_all_data[\"Tumor_Seq_Allele2\"].fillna(\"\").astype(str)\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_for_model = merged_all_data[[\"PATIENT_ID\", \"Cancer Type\", 'Cancer Type Detailed', 'Tumor Stage',\n",
    "                                'Sample Type', \"Sex\", \"Diagnosis Age\", \"Smoke Status\", \"TMB (nonsynonymous)\",\n",
    "                                \"Hugo_Symbol\", \"Chromosome\", \"Start_Position\", \"End_Position\",\n",
    "                                \"Consequence\", \"Variant_Type\", \"SNP_event\", \"Protein_position\", \"Codons\",\n",
    "                                \"Exon_Number\",\"VAR_TYPE_SX\", \"Site1_Hugo_Symbol\", \"Site2_Hugo_Symbol\",\"Event_Info\"]]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model[\"Exon_Number\"].isnull().sum()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model.head(20)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to handle the conversion\n",
    "def convert_exon_number(val):\n",
    "    try:\n",
    "        # First, try to convert to 'Month-Year' format (e.g., 'Sep-89' -> '09/89')\n",
    "        return pd.to_datetime(val, format='%b-%y').strftime('%m/%y')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Then, try to convert to 'DD-Mon' format (e.g., '14-Sep' -> '09/14')\n",
    "        date_obj = pd.to_datetime(val, format='%d-%b', errors='raise')\n",
    "        return date_obj.strftime('%m/%d')\n",
    "    except ValueError:\n",
    "        # If neither format matches, return the value as is (non-date-like string)\n",
    "        return val"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply the function to the column\n",
    "data_for_model.loc[:, 'Exon_Number'] = data_for_model['Exon_Number'].apply(convert_exon_number)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model[\"Exon_Number\"].isnull().sum()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model.to_csv('somatic_alterations_from_tumors.csv', index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model[\"Cancer Type\"].value_counts()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_age_range(x):\n",
    "    if x <= 10:\n",
    "        return \"0-10\"\n",
    "    elif x <= 20:\n",
    "        return \"11-20\"\n",
    "    elif x <= 30:\n",
    "        return \"21-30\"\n",
    "    elif x <= 40:\n",
    "        return \"31-40\"\n",
    "    elif x <= 50:\n",
    "        return \"41-50\"\n",
    "    elif x <= 60:\n",
    "        return \"51-60\"\n",
    "    elif x <= 70:\n",
    "        return \"61-70\"\n",
    "    elif x <= 80:\n",
    "        return \"71-80\"\n",
    "    else:\n",
    "        return \"80+\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model.loc[:, 'Diagnosis Age'] = data_for_model['Diagnosis Age'].astype(int).apply(create_age_range).astype(\"category\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tt = dict(enumerate(data_for_model[\"Exon_Number\"].astype('category').cat.categories))\n",
    "tt.values()\n",
    "# data[object_columns] = data[object_columns].astype('category')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter cancer types with at least 2000 samples\n",
    "cancer_counts = data_for_model['Cancer Type'].value_counts()\n",
    "valid_cancer_types = cancer_counts[cancer_counts >= 2000].index\n",
    "data_for_model = data_for_model[data_for_model['Cancer Type'].isin(valid_cancer_types)]\n",
    "data_for_model = data_for_model[data_for_model['Chromosome'].notnull()]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_lift = data_for_model.copy()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_lift[\"Consequence\"].unique()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_for_model['Consequence'].str.split(',')\n",
    "dummy_vars = data_for_model['Consequence'].str.split(',').explode().str.get_dummies().groupby(level=0).sum()\n",
    "data_for_model = data_for_model.join(dummy_vars)\n",
    "data_for_model.drop('Consequence', axis=1, inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model[data_for_model[\"PATIENT_ID\"] == \"Patient8178\"]"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model.to_csv(\"pan_cancer_data_for_model.csv\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "hypo_data = pd.read_csv(\"hypotheses.csv\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hypo_data_updates = hypo_data[hypo_data[\"support\"] > 2].sort_values([\"cancer_type\", 'support'], ascending=[True, False])\n",
    "hypo_data_updates.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cancer_type_correlations(df):\n",
    "    \"\"\"\n",
    "    Print cancer type and non-null feature-value pairs for each row in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns \"cancer_type\", feature columns, and \"support\".\n",
    "    \"\"\"\n",
    "    corr_list = []\n",
    "    # Iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract cancer type and support\n",
    "        cancer_type = row[\"cancer_type\"]\n",
    "        support = row[\"support\"]\n",
    "\n",
    "        # Get feature-value pairs where the feature value is not null\n",
    "        features = [\n",
    "            f\"{feature}={row[feature]}\"\n",
    "            for feature in df.columns\n",
    "            if feature not in {\"cancer_type\", \"support\"} and not pd.isnull(row[feature])\n",
    "        ]\n",
    "\n",
    "        # Format and print the result\n",
    "        features_str = \", \".join(features)\n",
    "        corr_list.append(f\"{cancer_type}: {features_str}, Support: {support}\")\n",
    "    return corr_list\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "corr_list = cancer_type_correlations(hypo_data_updates)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "corr_list"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lift Calculation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cancer_type_dummy = data_for_lift['Cancer Type'].str.get_dummies().groupby(level=0).sum()\n",
    "data_for_lift = data_for_lift.join(cancer_type_dummy)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_lift.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine columns to create specific mutation identifiers\n",
    "# data_for_lift['Mutation'] = data_for_lift['Chromosome'] + \"_\" + data_for_lift['Start_Position'].astype(str) + \"_\" + data_for_lift['Variant_Type']\n",
    "data_for_lift['Position'] = data_for_lift['Start_Position'].astype(str) + \"-\" + data_for_lift['End_Position'].astype(str)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_lift.to_csv(\"data_for_lift.csv\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select a subset of columns to analyze (e.g., most relevant ones)\n",
    "columns_to_combine = ['Sex', 'Smoke Status', 'Chromosome', 'Hugo_Symbol', 'SNP_event', \"Consequence\", 'Exon_Number',\n",
    "                      \"Diagnosis Age\", \"TMB (nonsynonymous)\", \"Position\", \"Protein_position\", \"Codons\", \"VAR_TYPE_SX\"]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cancer_probabilities = {cancer_type: data_for_lift[cancer_type].mean() for cancer_type in list(data_for_lift[\"Cancer Type\"].unique())}"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "cancer_probabilities"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    # Iterate over feature combinations\n",
    "# for num_features in range(2, 6):\n",
    "feature_combinations = list(combinations(columns_to_combine, 5))\n",
    "feature_combinations"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Precompute the mean probabilities for cancer types\n",
    "\n",
    "lifts = []\n",
    "\n",
    "for cancer_type, P_B in cancer_probabilities.items():\n",
    "    for feature in feature_combinations:\n",
    "        # Combine the selected features into a single feature\n",
    "        combined_feature = data_for_lift[list(feature)].astype(str).agg('_'.join, axis=1)\n",
    "\n",
    "        # Compute value counts for the combined feature\n",
    "        combined_counts = combined_feature.value_counts()\n",
    "        valid_features = combined_counts[combined_counts >= 100].index\n",
    "\n",
    "        if valid_features.empty:\n",
    "            continue  # Skip if no valid combined features\n",
    "\n",
    "        # Filter the combined feature to include only valid entries\n",
    "        filtered_data = combined_feature[combined_feature.isin(valid_features)]\n",
    "        P_A = filtered_data.value_counts(normalize=True)\n",
    "\n",
    "        # Compute joint probabilities for cancer type\n",
    "        joint_prob = (\n",
    "            filtered_data[data_for_lift[cancer_type] == 1]\n",
    "            .value_counts(normalize=True)\n",
    "            .reindex(P_A.index, fill_value=0)\n",
    "        )\n",
    "\n",
    "        # Calculate lift\n",
    "        lift = (joint_prob / (P_A * P_B)).round(2)\n",
    "\n",
    "        # Store results\n",
    "        lifts.append((cancer_type, feature, lift))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lifts = []\n",
    "# Probability of the cancer type\n",
    "for num_features in range(2, 6):\n",
    "    feature_combinations = list(combinations(columns_to_combine, num_features))\n",
    "    for cancer_type in cancer_type_dummy.columns:\n",
    "        P_B = data_for_lift[cancer_type].mean()\n",
    "        for feature in feature_combinations:\n",
    "            # Create a combined feature from three columns\n",
    "            combined_feature = data_for_lift[feature[0]].astype(str)\n",
    "\n",
    "            for f in feature[1:]:\n",
    "                combined_feature += \"_\" + data_for_lift[f].astype(str)\n",
    "            # combined_feature = \"_\".join(data_for_lift[feature].astype(str) for feature in feature_combinations)\n",
    "\n",
    "            min_count = 100\n",
    "            P_A_counts = combined_feature.value_counts()\n",
    "\n",
    "            # Filter combined features based on minimum count\n",
    "            valid_features = P_A_counts[P_A_counts >= min_count].index\n",
    "            filtered_data = combined_feature[combined_feature.isin(valid_features)]\n",
    "\n",
    "            # Probability of the combined feature\n",
    "            P_A = filtered_data.value_counts(normalize=True)\n",
    "\n",
    "            # Joint probability of the combined feature and cancer type\n",
    "            joint = (filtered_data[data_for_lift[cancer_type] == 1].value_counts(normalize=True).reindex(P_A.index, fill_value=0))\n",
    "\n",
    "            # Calculate lift\n",
    "            lift = (joint / (P_A * P_B)).round(2)  # Round lift to 2 decimal places for readability\n",
    "\n",
    "            # Append results as a tuple of the feature triplet and their associated lift values\n",
    "            lifts.append((cancer_type, feature, lift))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Flatten the results for easy visualization\n",
    "lift_results = []\n",
    "\n",
    "for cancer_type, feature_pair, lift in lifts:\n",
    "    for feature_value, lift_value in lift.items():\n",
    "        lift_results.append({\n",
    "            'Cancer Type': cancer_type,\n",
    "            'Feature Pair': feature_pair,\n",
    "            'Feature Value': feature_value,\n",
    "            'Lift': lift_value\n",
    "        })\n",
    "\n",
    "lift_df = pd.DataFrame(lift_results)\n",
    "lift_df = lift_df.sort_values(by='Lift', ascending=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "lift_df.sort_values(by='Lift', ascending=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "filter_triple_data = data[data[\"Smoke Status\"] == \"Nonsmoker\"]\n",
    "filter_triple_data = filter_triple_data[filter_triple_data[\"Hugo_Symbol\"] == \"TP53\"]\n",
    "filter_triple_data = filter_triple_data[filter_triple_data[\"SNP_event\"] == \"G>A\"]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def combine_features(data, feature_combination):\n",
    "    \"\"\"\n",
    "    Combine selected features into a single feature by joining their values.\n",
    "    \"\"\"\n",
    "    return data[list(feature_combination)].astype(str).agg('_'.join, axis=1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def filter_and_compute_probabilities(combined_feature, data_for_lift, cancer_type, min_count):\n",
    "    \"\"\"\n",
    "    Filter valid features, compute P(A), and joint probabilities for a cancer type.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute value counts\n",
    "    combined_counts = combined_feature.value_counts()\n",
    "    valid_features = combined_counts[combined_counts >= min_count].index\n",
    "\n",
    "    # Step 2: Skip if no valid combined features\n",
    "    if valid_features.empty:\n",
    "        return None, None\n",
    "\n",
    "    # Step 3: Filter the combined feature\n",
    "    filtered_data = combined_feature[combined_feature.isin(valid_features)]\n",
    "\n",
    "    # Step 4: Compute probabilities\n",
    "    P_A = filtered_data.value_counts(normalize=True)\n",
    "    joint_prob = (\n",
    "        filtered_data[data_for_lift[cancer_type] == 1]\n",
    "        .value_counts(normalize=True)\n",
    "        .reindex(P_A.index, fill_value=0)\n",
    "    )\n",
    "\n",
    "    return P_A, joint_prob\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_lifts_for_cancer_type(data_for_lift, cancer_type, P_B, feature_combinations, min_count):\n",
    "    \"\"\"\n",
    "    Compute lifts for a single cancer type across all feature combinations.\n",
    "    \"\"\"\n",
    "    lifts = []\n",
    "\n",
    "    for feature_combination in feature_combinations:\n",
    "        # Step 1: Combine features\n",
    "        combined_feature = combine_features(data_for_lift, feature_combination)\n",
    "\n",
    "        # Step 2: Filter and compute probabilities\n",
    "        P_A, joint_prob = filter_and_compute_probabilities(\n",
    "            combined_feature, data_for_lift, cancer_type, min_count\n",
    "        )\n",
    "\n",
    "        if P_A is None or joint_prob is None:\n",
    "            continue  # Skip if no valid combined features\n",
    "\n",
    "        # Step 3: Calculate lift\n",
    "        lift = (joint_prob / (P_A * P_B)).round(2)\n",
    "\n",
    "        # Step 4: Store result\n",
    "        lifts.append((cancer_type, feature_combination, lift))\n",
    "\n",
    "    return lifts"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_all_lifts(data_for_lift, cancer_probabilities, feature_combinations, min_count=100):\n",
    "    \"\"\"\n",
    "    Main function to compute lifts for all cancer types.\n",
    "    \"\"\"\n",
    "    all_lifts = []\n",
    "\n",
    "    for cancer_type, P_B in cancer_probabilities.items():\n",
    "        lifts = calculate_lifts_for_cancer_type(\n",
    "            data_for_lift, cancer_type, P_B, feature_combinations, min_count\n",
    "        )\n",
    "        all_lifts.extend(lifts)\n",
    "\n",
    "    return all_lifts"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "lifts = compute_all_lifts(data_for_lift, cancer_probabilities, feature_combinations, min_count=100)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_dr = pd.read_csv('data_for_rules.csv')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_dr.columns"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "narrowed = pd.read_csv(\"narrowed_cancers_data.csv\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "narrowed[narrowed.index == 529]"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "narrowed[['Current_Exon', 'Total_Exons']] = narrowed['Exon_Number'].str.split('/', expand=True)\n",
    "narrowed[['Current_Exon', 'Total_Exons']] = narrowed[['Current_Exon', 'Total_Exons']].astype(float)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "narrowed[[\"Current_Exon\", \"Total_Exons\"]] = imputer.fit_transform(narrowed[[\"Current_Exon\", \"Total_Exons\"]])\n",
    "# ransform(narrowed[[\"Exon_Number\"]])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "narrowed[[\"Exon_Number\", \"Current_Exon\", \"Total_Exons\"]]"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = pd.read_csv(\"data_for_rules.csv\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = df[df[\"Diagnosis Age\"] < 71.5]\n",
    "df = df[df[\"Diagnosis Age\"] > 47.5]\n",
    "df = df[df[\"TMB (nonsynonymous)\"] < 0.28]\n",
    "df = df[df[\"Sex\"] == \"Female\"]\n",
    "df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[\"Cancer Type\"].drop_duplicates()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[[\"PATIENT_ID\", \"Cancer Type\"]].drop_duplicates()[\"Cancer Type\"].value_counts()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "create dataframe for decision tree sentences"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules = pd.read_csv(\"data_for_rules.csv\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules['Exon_Number'].value_counts()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Smoke Status - Convert to dummies\n",
    "dummy_smoking = df_rules['Smoke Status'].str.get_dummies().groupby(level=0).sum()\n",
    "\n",
    "# Hugo Symbol - Convert to dummies\n",
    "dummy_hugo_symbol = df_rules['Hugo_Symbol'].str.get_dummies().groupby(level=0).sum()\n",
    "\n",
    "# Variant Type - Convert to dummies\n",
    "dummy_Variant_Type = df_rules['Variant_Type'].str.get_dummies().groupby(level=0).sum()\n",
    "\n",
    "# SNP_event - Keep only top 100 most frequent values\n",
    "top_100 = df_rules['SNP_event'].value_counts().nlargest(100).index\n",
    "df_rules['SNP_event'] = df_rules['SNP_event'].where(df_rules['SNP_event'].isin(top_100), other=None)\n",
    "dummy_snp_event = df_rules['SNP_event'].str.get_dummies().groupby(level=0).sum()\n",
    "\n",
    "# Combine all dummy variables\n",
    "dummy_vars = pd.concat([dummy_smoking, dummy_hugo_symbol, dummy_snp_event, dummy_Variant_Type], axis=1)\n",
    "\n",
    "# Join with original DataFrame\n",
    "df_rules = df_rules.join(dummy_vars)\n",
    "\n",
    "# Drop original categorical columns\n",
    "df_rules.drop(['Smoke Status', 'SNP_event', 'Hugo_Symbol', 'Variant_Type'], axis=1, inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(list(data_for_model[\"Event_Info\"].unique()))"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules[\"Cancer Type\"].unique()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules['Exon_Number'] = df_rules['Exon_Number'].str.split('/').str[0].astype(int)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules.drop('Codons', axis=1, inplace=True)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules.head(10)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_rules.to_csv(\"data_for_decision.csv\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = data_for_model.copy()\n",
    "df.drop(['Site1_Hugo_Symbol', 'Site2_Hugo_Symbol', 'Event_Info'], axis=1, inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_for_model.dropna(inplace=True)\n",
    "data_for_model['Exon_Number'] = data_for_model['Exon_Number'].str.split('/').str[0].astype(int)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1: Prepare your categorical features\n",
    "categorical_features = ['Sex', 'VAR_TYPE_SX', 'Smoke Status', 'Hugo_Symbol', 'Variant_Type', 'SNP_event', 'Consequence', 'Chromosome']\n",
    "\n",
    "# Step 2: Handle the special case of Codons\n",
    "def prepare_data(df, columns):\n",
    "    # For high-cardinality features like Codons, we can group them\n",
    "    # Example: Group by first letter of codon or by some domain knowledge\n",
    "\n",
    "    # Method 1: Keep only the most frequent codons and group others\n",
    "    for column in columns:\n",
    "        top_codons = df[column].value_counts().nlargest(100).index.tolist()\n",
    "        df[f'{column}_grouped'] = df[column].apply(lambda x: x if x in top_codons else 'Other')\n",
    "\n",
    "    # OR Method 2: Group by first nucleotide\n",
    "    # df['Codons_grouped'] = df['Codons'].apply(lambda x: x[0] + '_codons' if isinstance(x, str) else 'Unknown')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 3: Encoding categorical features\n",
    "def encode_features(df, categorical_cols):\n",
    "    label_encoders = {}\n",
    "\n",
    "    # Store original values for interpretation\n",
    "    feature_values = {}\n",
    "\n",
    "    for col in categorical_cols + ['SNP_event_grouped']:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col + '_encoded'] = le.fit_transform(df[col])\n",
    "\n",
    "            # Store mapping for interpretation\n",
    "            label_encoders[col] = le\n",
    "            feature_values[col] = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "    return df, label_encoders, feature_values\n",
    "\n",
    "def extract_rules(clf, feature_names, class_names, feature_values):\n",
    "    tree_ = clf.tree_\n",
    "\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != tree._tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "\n",
    "    def recurse(node, path, paths):\n",
    "        if tree_.feature[node] != tree._tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "\n",
    "            # Special handling for chromosome dummy variables\n",
    "            if name.startswith('chr_'):\n",
    "                # Extract chromosome number\n",
    "                chr_num = name.split('_')[1]\n",
    "\n",
    "                # For dummy variables, typically threshold is 0.5\n",
    "                if threshold <= 0.5:\n",
    "                    # chr_X ≤ 0.5 means the mutation is NOT on this chromosome\n",
    "                    path.append((name, \"chromosome\", {\"excluded\": chr_num}, f\"Chromosome is not {chr_num}\"))\n",
    "                    recurse(tree_.children_left[node], path, paths)\n",
    "                    path.pop()\n",
    "\n",
    "                    # chr_X > 0.5 means the mutation IS on this chromosome\n",
    "                    path.append((name, \"chromosome\", {\"included\": chr_num}, f\"Chromosome is {chr_num}\"))\n",
    "                    recurse(tree_.children_right[node], path, paths)\n",
    "                    path.pop()\n",
    "            # Handle categorical features\n",
    "            elif name.endswith('_encoded'):\n",
    "                original_name = name.replace('_encoded', '')\n",
    "\n",
    "                if original_name in feature_values:\n",
    "                    # Handle categorical feature\n",
    "                    left_values = [feature_values[original_name][i] for i in range(len(feature_values[original_name]))\n",
    "                                  if i <= threshold]\n",
    "                    right_values = [feature_values[original_name][i] for i in range(len(feature_values[original_name]))\n",
    "                                   if i > threshold]\n",
    "\n",
    "                    # Store as tuples: (feature_name, \"categorical\", values_list, readable_condition)\n",
    "                    if len(left_values) <= 3:\n",
    "                        left_condition = f\"{original_name} is {' or '.join(map(str, left_values))}\"\n",
    "                    else:\n",
    "                        left_condition = f\"{original_name} is in a group of {len(left_values)} values\"\n",
    "\n",
    "                   # Handle special case for Codons\n",
    "                    if original_name == 'SNP_event_grouped' and 'Other' in left_values:\n",
    "                        left_condition = f\"SNP event is among the less common types\"\n",
    "                    if original_name == 'SNP_event_grouped' and 'Other' in right_values:\n",
    "                        right_condition = f\"SNP event is among the less common types\"\n",
    "\n",
    "                    path.append((original_name, \"categorical\", set(left_values), left_condition))\n",
    "                    recurse(tree_.children_left[node], path, paths)\n",
    "                    path.pop()\n",
    "\n",
    "                    if len(right_values) <= 3:\n",
    "                        right_condition = f\"{original_name} is {' or '.join(map(str, right_values))}\"\n",
    "                    else:\n",
    "                        right_condition = f\"{original_name} is in a group of {len(right_values)} values\"\n",
    "\n",
    "                    path.append((original_name, \"categorical\", set(right_values), right_condition))\n",
    "                    recurse(tree_.children_right[node], path, paths)\n",
    "                    path.pop()\n",
    "                else:\n",
    "                    # Standard case for encoded features without mapping\n",
    "                    path.append((original_name, \"categorical\", {f\"≤ category {threshold:.0f}\"},\n",
    "                                f\"{original_name} ≤ category {threshold:.0f}\"))\n",
    "                    recurse(tree_.children_left[node], path, paths)\n",
    "                    path.pop()\n",
    "\n",
    "                    path.append((original_name, \"categorical\", {f\"> category {threshold:.0f}\"},\n",
    "                                f\"{original_name} > category {threshold:.0f}\"))\n",
    "                    recurse(tree_.children_right[node], path, paths)\n",
    "                    path.pop()\n",
    "            else:\n",
    "                # Numerical features - ensure we use consistent 4-tuple format\n",
    "                left_condition = f\"{name} ≤ {threshold:.2f}\"\n",
    "                path.append((name, \"numerical\", {\"min\": float(\"-inf\"), \"max\": threshold}, left_condition))\n",
    "                recurse(tree_.children_left[node], path, paths)\n",
    "                path.pop()\n",
    "\n",
    "                right_condition = f\"{name} > {threshold:.2f}\"\n",
    "                path.append((name, \"numerical\", {\"min\": threshold, \"max\": float(\"inf\")}, right_condition))\n",
    "                recurse(tree_.children_right[node], path, paths)\n",
    "                path.pop()\n",
    "        else:\n",
    "            class_idx = np.argmax(tree_.value[node][0])\n",
    "            paths.append((path.copy(), class_names[class_idx]))\n",
    "\n",
    "    recurse(0, [], paths)\n",
    "\n",
    "    # Generate human-readable sentences with consolidated features\n",
    "    rules = []\n",
    "    for path, outcome in paths:\n",
    "        if path:\n",
    "            # Group by feature name\n",
    "            feature_groups = {}\n",
    "            for condition in path:\n",
    "                feature, cond_type, value_info, readable = condition  # Now this should always work\n",
    "                if feature not in feature_groups:\n",
    "                    feature_groups[feature] = []\n",
    "                feature_groups[feature].append((cond_type, value_info, readable))\n",
    "\n",
    "            # Process chromosome features\n",
    "            chromosomes_included = []\n",
    "            chromosomes_excluded = []\n",
    "            other_feature_groups = {}\n",
    "\n",
    "            for feature, conditions in feature_groups.items():\n",
    "                if any(c[0] == \"chromosome\" for c in conditions):\n",
    "                    for cond_type, value_info, _ in conditions:\n",
    "                        if \"included\" in value_info:\n",
    "                            chromosomes_included.append(value_info[\"included\"])\n",
    "                        if \"excluded\" in value_info:\n",
    "                            chromosomes_excluded.append(value_info[\"excluded\"])\n",
    "                else:\n",
    "                    other_feature_groups[feature] = conditions\n",
    "\n",
    "            # Create consolidated conditions\n",
    "            consolidated_conditions = []\n",
    "\n",
    "            # Add chromosome conditions\n",
    "            if chromosomes_included:\n",
    "                if len(chromosomes_included) == 1:\n",
    "                    consolidated_conditions.append(f\"Chromosome is {chromosomes_included[0]}\")\n",
    "                else:\n",
    "                    consolidated_conditions.append(f\"Chromosome is one of {', '.join(chromosomes_included)}\")\n",
    "\n",
    "            if chromosomes_excluded:\n",
    "                if len(chromosomes_excluded) <= 3:\n",
    "                    consolidated_conditions.append(f\"Chromosome is not {', '.join(chromosomes_excluded)}\")\n",
    "\n",
    "            # Process other features\n",
    "            for feature, conditions in other_feature_groups.items():\n",
    "                if all(c[0] == \"numerical\" for c in conditions):\n",
    "                    # For numerical features\n",
    "                    min_val = float(\"-inf\")\n",
    "                    max_val = float(\"inf\")\n",
    "\n",
    "                    for _, value_info, _ in conditions:\n",
    "                        min_val = max(min_val, value_info.get(\"min\", float(\"-inf\")))\n",
    "                        max_val = min(max_val, value_info.get(\"max\", float(\"inf\")))\n",
    "\n",
    "                    if min_val > float(\"-inf\") and max_val < float(\"inf\"):\n",
    "                        consolidated_conditions.append(f\"{feature} is between {min_val:.2f} and {max_val:.2f}\")\n",
    "                    elif min_val > float(\"-inf\"):\n",
    "                        consolidated_conditions.append(f\"{feature} > {min_val:.2f}\")\n",
    "                    elif max_val < float(\"inf\"):\n",
    "                        consolidated_conditions.append(f\"{feature} ≤ {max_val:.2f}\")\n",
    "\n",
    "                elif all(c[0] == \"categorical\" for c in conditions):\n",
    "                    # For categorical features - find intersection of values\n",
    "                    value_sets = [c[1] for c in conditions]\n",
    "\n",
    "                    # Find intersection of all sets\n",
    "                    common_values = set.intersection(*value_sets) if value_sets else set()\n",
    "\n",
    "                    # If intersection is non-empty, it's the stricter condition\n",
    "                    if common_values:\n",
    "                        if len(common_values) <= 3:\n",
    "                            consolidated_conditions.append(f\"{feature} is {' or '.join(map(str, common_values))}\")\n",
    "                        else:\n",
    "                            consolidated_conditions.append(f\"{feature} is in a group of {len(common_values)} values\")\n",
    "                    else:\n",
    "                        # If no intersection (shouldn't happen in a valid tree), use original conditions\n",
    "                        for _, _, readable in conditions:\n",
    "                            consolidated_conditions.append(readable)\n",
    "\n",
    "            # Create the final rule\n",
    "            rule = \"If \" + \" AND \".join(consolidated_conditions) + f\", THEN cancer type is {outcome}\"\n",
    "            rules.append(rule)\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = df_rules.copy()\n",
    "df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# d = prepare_data(df)\n",
    "df, label_encoders, feature_values = encode_features(df, ['Sex', 'VAR_TYPE_SX'])\n",
    "df.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "features_to_drop = ['Cancer Type', 'Cancer Type Detailed', 'Tumor Stage', 'Sample Type', 'Sex', 'VAR_TYPE_SX']\n",
    "                    # 'Smoke Status', 'Hugo_Symbol', 'Variant_Type', 'SNP_event', 'SNP_event_grouped', 'Codons', 'Consequence', 'Chromosome']\n",
    "y = df['Cancer Type']\n",
    "X = df.drop(features_to_drop, axis=1)\n",
    "X_train, X_test, y_train, y_test, X_test_with_id = stratified_split_by_patient(X, y)\n",
    "feature_names = list(X_train.columns)\n",
    "class_names = list(df['Cancer Type'].unique())\n",
    "clf = tree.DecisionTreeClassifier(random_state=39)#, min_samples_leaf=10)#, max_depth=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "sentences = extract_rules(clf, feature_names, class_names, feature_values)\n",
    "\n",
    "# for sentence in sentences:\n",
    "#     print(sentence)\n",
    "sentences"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "feature_names"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data_for_model.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = prepare_data(data_for_model, ['SNP_event', 'Codons',])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv('models_hypotheses/combined_hypotheses.csv')\n",
    "df['plausibility'] = None\n",
    "df['novelty'] = None\n",
    "df['comments'] = None"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[df['rank'] <= 10].to_excel('models_hypotheses/hypotheses_for_professional_evaluation.xlsx', index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['Tumor Stage'].value_counts()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data = df[df['Tumor Stage'] in ['III', 'IV', 'II', 'I']]"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_latest_csv(directory):\n",
    "    list_of_files = glob.glob(os.path.join(directory, '*.csv'))\n",
    "    if not list_of_files:\n",
    "        raise FileNotFoundError(\"No CSV files found in the directory.\")\n",
    "    latest_file = max(list_of_files, key=os.path.getmtime)\n",
    "    print(f\"Using file: {latest_file}\")\n",
    "    return latest_file"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "latest_csv_path = get_latest_csv(\"llm_results\")\n",
    "df = pd.read_csv(latest_csv_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# df = pd.read_csv('llm_results/evaluations_20250409_151350.csv')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "combine_hyp = pd.read_csv('models_hypotheses/combined_hypotheses.csv')\n",
    "combine_hyp.rename(columns={'hypo_id': 'hypothesis_id'}, inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Make sure both columns are the same type (e.g., convert both to string or both to int)\n",
    "df['hypothesis_id'] = df['hypothesis_id'].astype(str)\n",
    "combine_hyp['hypothesis_id'] = combine_hyp['hypothesis_id'].astype(str)\n",
    "\n",
    "# Now you can safely join\n",
    "merged_df = df.join(combine_hyp.set_index('hypothesis_id'), on='hypothesis_id')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "merged_df.sort_values(by=['novelty', 'plausibility'], ascending=[False, False], inplace=True)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = merged_df[merged_df['novelty'] >= 6]\n",
    "data = data[data['plausibility'] >= 6]\n",
    "data = data[(data['novelty'] > 6) | (data['plausibility'] > 6)]\n",
    "# data['novelty'] = None\n",
    "# data['plausibility'] = None\n",
    "data.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "merged_df[(merged_df['novelty'] == merged_df['plausibility'])]\n",
    "# merged_df[merged_df[\"model\"] == \"openai:o3-mini\"]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "data.to_excel('models_hypotheses/hypotheses_for_professional2.xlsx', index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_data(filepath):\n",
    "    features_to_drop = ['Cancer Type Detailed', 'Tumor Stage', 'Sample Type', \"Site2_Hugo_Symbol\", \"Site1_Hugo_Symbol\", \"Event_Info\"]\n",
    "    label = 'Cancer Type'\n",
    "    data = pd.read_csv(filepath)\n",
    "    cancer_types = data[\"Cancer Type\"].unique()\n",
    "    # mapping = {}\n",
    "    # # Convert object columns to categorical\n",
    "    # object_columns = data.select_dtypes(include=['object', 'bool']).columns\n",
    "    # for col in object_columns:\n",
    "    #     mapping[col] = dict(enumerate(data[col].astype('category').cat.categories))\n",
    "    # data[object_columns] = data[object_columns].astype('category')\n",
    "    #\n",
    "    # # Encode categorical columns using cat.codes\n",
    "    # for col in data.select_dtypes(include='category').columns:\n",
    "    #     data[col] = data[col].cat.codes\n",
    "\n",
    "    # Separate features and labels\n",
    "    data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    X = data.drop(label, axis=1)\n",
    "    y, uniques = pd.factorize(data['Cancer Type'])\n",
    "    # label_dict = {cancer: idx for idx, cancer in enumerate(cancer_types)}\n",
    "    # X.replace(-1, np.nan, inplace=True)\n",
    "    return X, y#, label_dict, mapping\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def stratified_split_by_patient(X, y, train_ratio=0.7, test_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets with stratification by PATIENT_ID.\n",
    "    \"\"\"\n",
    "    # Ensure the ratios sum to 1\n",
    "    assert train_ratio + test_ratio == 1, \"Ratios must sum to 1.\"\n",
    "\n",
    "    # Get unique patient IDs\n",
    "    unique_ids = X['PATIENT_ID'].unique()\n",
    "\n",
    "    # Map PATIENT_ID to a corresponding target value (first occurrence)\n",
    "    patient_labels = dict(zip(X['PATIENT_ID'], y))\n",
    "    unique_patient_labels = [patient_labels[pid] for pid in unique_ids]\n",
    "\n",
    "    # Initial split: train+val and test\n",
    "    train_ids, test_ids = train_test_split(\n",
    "        unique_ids,\n",
    "        test_size=test_ratio,\n",
    "        stratify=unique_patient_labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Split data into subsets\n",
    "    X_train = X[X['PATIENT_ID'].isin(train_ids)].drop(columns=['PATIENT_ID'])\n",
    "    X_test = X[X['PATIENT_ID'].isin(test_ids)].drop(columns=['PATIENT_ID'])\n",
    "    X_test_with_id = X[X['PATIENT_ID'].isin(test_ids)]  # Keep validation set with PATIENT_ID for patient-level analysis\n",
    "\n",
    "    y_train = y[X['PATIENT_ID'].isin(train_ids)]\n",
    "    # y_val = y[X['PATIENT_ID'].isin(val_ids)]\n",
    "    y_test = y[X['PATIENT_ID'].isin(test_ids)]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, X_test_with_id"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def analyze_feature_combinations_for_cancer(model, X, y, cancer_type, cancer_names,\n",
    "                                           top_n=5, cat_features=None,\n",
    "                                           interaction_depth=2):\n",
    "    \"\"\"\n",
    "    Analyze feature combinations specific to a cancer type\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : CatBoostClassifier\n",
    "        Trained model\n",
    "    X : DataFrame\n",
    "        Feature data\n",
    "    y : Series\n",
    "        Target labels\n",
    "    cancer_type : int\n",
    "        The specific cancer type to analyze\n",
    "    cancer_names : list\n",
    "        List of cancer type names corresponding to encoded values\n",
    "    top_n : int\n",
    "        Number of top combinations to return\n",
    "    cat_features : list\n",
    "        List of categorical feature names\n",
    "    interaction_depth : int\n",
    "        Max number of features to consider in combinations\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import shap\n",
    "\n",
    "    # Get actual cancer name\n",
    "    cancer_name = cancer_names[cancer_type]\n",
    "\n",
    "    # Get samples for this cancer type\n",
    "    cancer_indices = np.where(y == cancer_type)[0]\n",
    "    X_cancer = X.iloc[cancer_indices]\n",
    "\n",
    "    # Get samples for other cancer types\n",
    "    other_indices = np.where(y != cancer_type)[0]\n",
    "    X_other = X.iloc[other_indices]\n",
    "\n",
    "    print(f\"\\n===== ANALYZING CANCER TYPE: {cancer_name} =====\")\n",
    "    print(f\"Number of samples: {len(X_cancer)}\")\n",
    "\n",
    "    # Get feature importance for this specific cancer type\n",
    "    # Use SHAP values for better feature importance\n",
    "    try:\n",
    "        print(\"\\nCalculating SHAP values for feature importance...\")\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        # Get class-specific SHAP values\n",
    "        # Sample for efficiency if dataset is large\n",
    "        sample_size = min(len(X), 1000)\n",
    "        X_sample = X.sample(sample_size, random_state=42)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "        # Get SHAP values for this cancer type\n",
    "        cancer_shap = shap_values[cancer_type]\n",
    "\n",
    "        # Calculate mean absolute SHAP value for each feature\n",
    "        feature_importance = np.abs(cancer_shap).mean(0)\n",
    "        feature_names = X.columns\n",
    "\n",
    "        # Sort features by importance\n",
    "        sorted_idx = np.argsort(-feature_importance)\n",
    "\n",
    "        # Plot SHAP values\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        shap.summary_plot(cancer_shap, X_sample, plot_type=\"bar\", show=False)\n",
    "        plt.title(f'SHAP Feature Importance for {cancer_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # List top important features\n",
    "        print(f\"\\nTop features for {cancer_name}:\")\n",
    "        for i in range(min(10, len(sorted_idx))):\n",
    "            idx = sorted_idx[i]\n",
    "            print(f\"{feature_names[idx]}: {feature_importance[idx]:.4f}\")\n",
    "\n",
    "        # Get top features for interaction analysis\n",
    "        top_features = [feature_names[i] for i in sorted_idx[:15]]  # Use top 15 features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP analysis error: {e}\")\n",
    "        print(\"Falling back to CatBoost feature importance\")\n",
    "\n",
    "        # Use CatBoost feature importance\n",
    "        feature_importance = model.get_feature_importance()\n",
    "        feature_names = X.columns\n",
    "        sorted_idx = np.argsort(-feature_importance)\n",
    "\n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.barh(range(min(15, len(sorted_idx))),\n",
    "                feature_importance[sorted_idx[:15]])\n",
    "        plt.yticks(range(min(15, len(sorted_idx))),\n",
    "                  [feature_names[i] for i in sorted_idx[:15]])\n",
    "        plt.title(f'Feature Importance for {cancer_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Get top features for interaction analysis\n",
    "        top_features = [feature_names[i] for i in sorted_idx[:15]]  # Use top 15 features\n",
    "\n",
    "    # Analyze feature distributions for this cancer type vs others\n",
    "    print(\"\\nAnalyzing feature distributions...\")\n",
    "\n",
    "    # Select features for analysis (mix of top important and categorical)\n",
    "    analysis_features = top_features.copy()\n",
    "    if cat_features:\n",
    "        for cf in cat_features:\n",
    "            if cf not in analysis_features:\n",
    "                analysis_features.append(cf)\n",
    "\n",
    "    # Keep unique features only\n",
    "    analysis_features = list(set(analysis_features))\n",
    "\n",
    "    # Analyze individual feature distributions\n",
    "    for feature in analysis_features[:10]:  # Limit to top 10 for clarity\n",
    "        if feature in cat_features if cat_features else []:\n",
    "            # Categorical feature analysis\n",
    "            cancer_dist = X_cancer[feature].value_counts(normalize=True)\n",
    "            other_dist = X_other[feature].value_counts(normalize=True)\n",
    "\n",
    "            # Compute lift ratio (how much more likely in this cancer type)\n",
    "            lift = pd.DataFrame({\n",
    "                'Cancer': cancer_dist,\n",
    "                'Other': other_dist\n",
    "            }).fillna(0)\n",
    "            lift['Lift'] = lift['Cancer'] / lift['Other'].replace(0, 0.001)\n",
    "            lift = lift.sort_values('Lift', ascending=False)\n",
    "\n",
    "            print(f\"\\nFeature: {feature}\")\n",
    "            print(\"Top values by lift ratio:\")\n",
    "            print(lift[['Cancer', 'Other', 'Lift']].head(3))\n",
    "\n",
    "            # Plot distribution comparison\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            # Get top categories by frequency\n",
    "            top_cats = set(cancer_dist.nlargest(5).index) | set(other_dist.nlargest(5).index)\n",
    "\n",
    "            # Filter both distributions to these categories\n",
    "            plot_data = pd.DataFrame({\n",
    "                f'{cancer_name}': cancer_dist.reindex(top_cats).fillna(0),\n",
    "                'Other Cancer Types': other_dist.reindex(top_cats).fillna(0)\n",
    "            })\n",
    "\n",
    "            plot_data.plot(kind='bar', ax=plt.gca())\n",
    "            plt.title(f'Distribution of {feature} ({cancer_name} vs Others)')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Numerical feature analysis - Fix for TypeError\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            # Check if feature is numeric\n",
    "            if pd.api.types.is_numeric_dtype(X[feature]):\n",
    "                # KDE plot for numeric data\n",
    "                sns.kdeplot(X_cancer[feature].astype(float), label=f'{cancer_name}')\n",
    "                sns.kdeplot(X_other[feature].astype(float), label='Other Cancer Types')\n",
    "                plt.title(f'Distribution of {feature} ({cancer_name} vs Others)')\n",
    "                plt.xlabel(feature)\n",
    "                plt.ylabel('Density')\n",
    "                plt.legend()\n",
    "            else:\n",
    "                # For non-numeric data, use countplot instead of kdeplot\n",
    "                plot_data = pd.DataFrame({\n",
    "                    'value': pd.concat([X_cancer[feature], X_other[feature]]),\n",
    "                    'group': (['This Cancer'] * len(X_cancer)) + (['Other Cancers'] * len(X_other))\n",
    "                })\n",
    "                sns.countplot(x='value', hue='group', data=plot_data)\n",
    "                plt.title(f'Distribution of {feature} ({cancer_name} vs Others)')\n",
    "                plt.xlabel(feature)\n",
    "                plt.ylabel('Count')\n",
    "                plt.xticks(rotation=45)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Calculate statistics for numeric features\n",
    "            if pd.api.types.is_numeric_dtype(X[feature]):\n",
    "                cancer_mean = X_cancer[feature].mean()\n",
    "                other_mean = X_other[feature].mean()\n",
    "                mean_diff_pct = ((cancer_mean - other_mean) / other_mean * 100\n",
    "                                if other_mean != 0 else float('inf'))\n",
    "\n",
    "                print(f\"\\nFeature: {feature}\")\n",
    "                print(f\"Mean for {cancer_name}: {cancer_mean:.4f}\")\n",
    "                print(f\"Mean for Other Cancer Types: {other_mean:.4f}\")\n",
    "                print(f\"Difference: {mean_diff_pct:.2f}%\")\n",
    "\n",
    "    # Feature interaction analysis\n",
    "    if cat_features and len(cat_features) >= 2:\n",
    "        print(\"\\nAnalyzing categorical feature interactions...\")\n",
    "\n",
    "        # Select categorical features for analysis\n",
    "        cat_features_for_analysis = [f for f in analysis_features if f in cat_features]\n",
    "        cat_features_for_analysis = cat_features_for_analysis[:min(len(cat_features_for_analysis), 5)]\n",
    "\n",
    "        if len(cat_features_for_analysis) >= 2:\n",
    "            feature_combinations = []\n",
    "\n",
    "            # Analyze pairwise combinations\n",
    "            for i, feat1 in enumerate(cat_features_for_analysis):\n",
    "                for feat2 in cat_features_for_analysis[i+1:]:\n",
    "                    # Get value counts for both features in cancer subset\n",
    "                    combo_cancer = X_cancer.groupby([feat1, feat2]).size().reset_index()\n",
    "                    combo_cancer.columns = [feat1, feat2, 'cancer_count']\n",
    "                    combo_cancer['cancer_pct'] = combo_cancer['cancer_count'] / len(X_cancer) * 100\n",
    "\n",
    "                    # Get value counts for both features in other subset\n",
    "                    combo_other = X_other.groupby([feat1, feat2]).size().reset_index()\n",
    "                    combo_other.columns = [feat1, feat2, 'other_count']\n",
    "                    combo_other['other_pct'] = combo_other['other_count'] / len(X_other) * 100\n",
    "\n",
    "                    # Merge and calculate lift\n",
    "                    combo_merged = pd.merge(combo_cancer, combo_other, on=[feat1, feat2], how='left')\n",
    "                    combo_merged.fillna({'other_count': 0, 'other_pct': 0.001}, inplace=True)\n",
    "                    combo_merged['lift'] = combo_merged['cancer_pct'] / combo_merged['other_pct']\n",
    "\n",
    "                    # Filter to significant combinations (with enough samples)\n",
    "                    combo_merged = combo_merged[combo_merged['cancer_count'] >= 5]\n",
    "\n",
    "                    # Sort by lift\n",
    "                    combo_merged.sort_values('lift', ascending=False, inplace=True)\n",
    "\n",
    "                    # Add top combinations to results\n",
    "                    for _, row in combo_merged.head(3).iterrows():\n",
    "                        feature_combinations.append({\n",
    "                            'Feature1': feat1,\n",
    "                            'Value1': row[feat1],\n",
    "                            'Feature2': feat2,\n",
    "                            'Value2': row[feat2],\n",
    "                            'Cancer_Count': row['cancer_count'],\n",
    "                            'Cancer_Pct': row['cancer_pct'],\n",
    "                            'Other_Pct': row['other_pct'],\n",
    "                            'Lift': row['lift']\n",
    "                        })\n",
    "\n",
    "            # Sort all combinations by lift and display top results\n",
    "            if feature_combinations:\n",
    "                combinations_df = pd.DataFrame(feature_combinations)\n",
    "                combinations_df.sort_values('Lift', ascending=False, inplace=True)\n",
    "\n",
    "                print(f\"\\nTop feature combinations for {cancer_name}:\")\n",
    "                pd.set_option('display.max_colwidth', 30)\n",
    "                print(combinations_df.head(top_n))\n",
    "\n",
    "                # Plot top combinations\n",
    "                plt.figure(figsize=(14, 8))\n",
    "                bars = plt.barh(range(len(combinations_df.head(top_n))),\n",
    "                                combinations_df.head(top_n)['Lift'],\n",
    "                                color='skyblue')\n",
    "                plt.yticks(range(len(combinations_df.head(top_n))),\n",
    "                          [f\"{row['Feature1']}={row['Value1']}, {row['Feature2']}={row['Value2']}\"\n",
    "                           for _, row in combinations_df.head(top_n).iterrows()])\n",
    "                plt.xlabel('Lift (How much more common in this cancer type)')\n",
    "                plt.title(f'Top Feature Combinations for {cancer_name}')\n",
    "\n",
    "                # Add value labels\n",
    "                for i, bar in enumerate(bars):\n",
    "                    plt.text(bar.get_width() + 0.2,\n",
    "                            bar.get_y() + bar.get_height()/2,\n",
    "                            f\"{combinations_df.iloc[i]['Lift']:.2f}x\",\n",
    "                            va='center')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"No significant feature combinations found.\")\n",
    "        else:\n",
    "            print(\"Not enough categorical features for combination analysis.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main():\n",
    "    # Import necessary libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from catboost import CatBoostClassifier, Pool\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # Load your data here\n",
    "    features_to_drop = ['Cancer Type Detailed', 'Tumor Stage', 'Sample Type', \"Site2_Hugo_Symbol\", \"Site1_Hugo_Symbol\", \"Event_Info\"]\n",
    "    label = 'Cancer Type'\n",
    "    data = pd.read_csv(\"narrowed_cancers_data.csv\")\n",
    "    data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    X = data.drop(label, axis=1)\n",
    "\n",
    "    # Get cancer names and encoded values\n",
    "    y, cancer_names = pd.factorize(data['Cancer Type'])\n",
    "    cancer_names = cancer_names.tolist()  # Convert to list for indexing\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, X_test_with_id = stratified_split_by_patient(X, y)\n",
    "    categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Create CatBoost Pool with categorical features identified\n",
    "    train_pool = Pool(X_train, y_train, cat_features=categorical_columns)\n",
    "    test_pool = Pool(X_test, y_test, cat_features=categorical_columns)\n",
    "\n",
    "    # Initialize and train CatBoost model\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        loss_function='MultiClass',\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    model.fit(train_pool)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    print(\"\\nModel evaluation:\")\n",
    "    predictions = model.predict(X_test)\n",
    "    pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions, target_names=cancer_names))\n",
    "\n",
    "    cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # ====== FEATURE COMBINATION ANALYSIS FOR EACH CANCER TYPE ======\n",
    "    print(\"Analyzing feature combinations for each cancer type...\")\n",
    "    unique_cancer_types = np.unique(y)\n",
    "\n",
    "    for cancer_type in unique_cancer_types:\n",
    "        analyze_feature_combinations_for_cancer(\n",
    "            model, X, y, cancer_type, cancer_names,\n",
    "            top_n=5, cat_features=cat_features\n",
    "        )\n",
    "\n",
    "    print(\"Analysis complete!\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X, y = load_data(\"narrowed_cancers_data.csv\")\n",
    "X_train, X_test, y_train, y_test, X_test_with_id = stratified_split_by_patient(X, y)\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nCategorical columns: {categorical_columns}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Create CatBoost Pool with categorical features identified\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_columns)\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_columns)\n",
    "\n",
    "# Initialize and train CatBoost model\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model.fit(train_pool)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Evaluate model performance\n",
    "print(\"\\nModel evaluation:\")\n",
    "predictions = model.predict(X_test)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "counts = data_for_model.groupby('Site2_Hugo_Symbol')['PATIENT_ID'].nunique()\n",
    "counts\n",
    "# counts[counts.index == \"CCDC149\"]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = pd.read_csv(\"narrowed_cancers_data.csv\")"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = df[df[\"TMB (nonsynonymous)\"] == 0.3]\n",
    "df = df[df[\"SNP_event\"] == \"A>T\"]\n",
    "# df = df[df[\"Cancer Type\"] == \"Liver Hepatocellular Carcinoma\"]\n",
    "# df = df[df[\"Sex\"] == \"Male\"]\n",
    "# df.groupby(\"Sex\").size()\n",
    "# df[\"Event\"]\n",
    "# Count unique PATIENT_ID per Cancer Type and Codons\n",
    "# counts = df.groupby([\"Cancer Type\", \"Codons\"])[\"PATIENT_ID\"].nunique().reset_index(name=\"patient_count\")\n",
    "# counts.sort_values(by=[\"Cancer Type\", \"patient_count\"], ascending=[True, False])\n",
    "df.groupby(\"Cancer Type\")[\"Sex\"].value_counts()\n",
    "# df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "TMB (nonsynonymous) value is 0.3 AND Sex value is Male AND SNP event value is A>T' leads to liver hepatocellular carcinoma\""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
