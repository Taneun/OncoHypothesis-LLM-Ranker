{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T10:19:54.121713Z",
     "start_time": "2025-05-28T10:19:44.497070Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T10:21:33.739011Z",
     "start_time": "2025-05-28T10:21:33.707212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(filepath):\n",
    "    features_to_drop = ['Cancer Type', 'Cancer Type Detailed', 'Tumor Stage', 'Sample Type']\n",
    "    data = pd.read_csv(filepath)\n",
    "    cancer_types = data[\"Cancer Type\"].unique()\n",
    "    mapping = {}\n",
    "    # Convert object columns to categorical\n",
    "    object_columns = data.select_dtypes(include=['object', 'bool']).columns\n",
    "    for col in object_columns:\n",
    "        mapping[col] = dict(enumerate(data[col].astype('category').cat.categories))\n",
    "    data[object_columns] = data[object_columns].astype('category')\n",
    "\n",
    "    # Encode categorical columns using cat.codes\n",
    "    for col in data.select_dtypes(include='category').columns:\n",
    "        data[col] = data[col].cat.codes\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = data.drop(features_to_drop, axis=1)\n",
    "    y, uniques = pd.factorize(data['Cancer Type'])\n",
    "    label_dict = {cancer: idx for idx, cancer in enumerate(cancer_types)}\n",
    "    X.replace(-1, np.nan, inplace=True)\n",
    "    return X, y, label_dict, mapping\n",
    "\n",
    "\n",
    "def stratified_split_by_patient(X, y, train_ratio=0.7, test_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets with stratification by PATIENT_ID.\n",
    "    \"\"\"\n",
    "    # Ensure the ratios sum to 1\n",
    "    assert train_ratio + test_ratio == 1, \"Ratios must sum to 1.\"\n",
    "\n",
    "    # Get unique patient IDs\n",
    "    unique_ids = X['PATIENT_ID'].unique()\n",
    "\n",
    "    # Map PATIENT_ID to a corresponding target value (first occurrence)\n",
    "    patient_labels = dict(zip(X['PATIENT_ID'], y))\n",
    "    unique_patient_labels = [patient_labels[pid] for pid in unique_ids]\n",
    "\n",
    "    # Initial split: train+val and test\n",
    "    train_ids, test_ids = train_test_split(\n",
    "        unique_ids,\n",
    "        test_size=test_ratio,\n",
    "        stratify=unique_patient_labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Split data into subsets\n",
    "    X_train = X[X['PATIENT_ID'].isin(train_ids)].drop(columns=['PATIENT_ID'])\n",
    "    X_test = X[X['PATIENT_ID'].isin(test_ids)].drop(columns=['PATIENT_ID'])\n",
    "    X_test_with_id = X[X['PATIENT_ID'].isin(test_ids)]  # Keep validation set with PATIENT_ID for patient-level analysis\n",
    "\n",
    "    y_train = y[X['PATIENT_ID'].isin(train_ids)]\n",
    "    # y_val = y[X['PATIENT_ID'].isin(val_ids)]\n",
    "    y_test = y[X['PATIENT_ID'].isin(test_ids)]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, X_test_with_id"
   ],
   "id": "92c003385d73f474",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T10:21:38.538808Z",
     "start_time": "2025-05-28T10:21:37.819230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load SHAP values and data\n",
    "shap_values = np.load(\"shap_values.npy\")  # shape: (14535, 42, 12)\n",
    "X, y, label_dict, mapping = load_data(\"narrowed_cancers_data.csv\")\n",
    "X_train, X_test, y_train, y_test, X_test_with_id = stratified_split_by_patient(X, y)\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Step 1: Compute mean absolute SHAP values over samples\n",
    "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)  # shape: (42, 12)\n",
    "\n",
    "# Step 2: Compute total importance per feature and get top 10 indices\n",
    "total_importance = mean_abs_shap.sum(axis=1)  # shape: (42,)\n",
    "top_indices = np.argsort(total_importance)[-10:][::-1]  # Top 10, descending order\n",
    "\n",
    "# Step 3: Slice the matrix and feature names for top 10\n",
    "top_features_shap = mean_abs_shap[top_indices]  # shape: (10, 12)\n",
    "top_feature_names = feature_names[top_indices]\n",
    "\n",
    "# Step 4: Plotting\n",
    "label_names = list(label_dict.keys())\n",
    "colors = plt.cm.get_cmap(\"tab20\", len(label_names))"
   ],
   "id": "85e6f071c3471aba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/jy0q_s_94s389s75171djrp40000gn/T/ipykernel_6571/3628554179.py:20: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab20\", len(label_names))\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "bottom = np.zeros(len(top_feature_names))\n",
    "\n",
    "for i in range(len(label_names)):\n",
    "    values = top_features_shap[:, i]\n",
    "    ax.barh(top_feature_names, values, left=bottom, color=colors(i), label=label_names[i])\n",
    "    bottom += values\n",
    "\n",
    "ax.set_xlabel(\"Mean Absolute SHAP Value\")\n",
    "ax.set_title(\"Top 10 Features (XGBoost): Mean Absolute SHAP Value per Class\")\n",
    "ax.invert_yaxis()  # Most important feature at top\n",
    "ax.legend(title=\"Cancer Type\", bbox_to_anchor=(0.5, 0.7), loc='upper left', prop={'size': 12})\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"top_10_features_shap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "a3bf04b2d51ffe5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "explainer = pickle.load(open(\"/Users/talneumann/PycharmProjects/llm-project/pan_cancer/models_and_explainers/LightGBM_explainer.pkl\", \"rb\"))\n",
    "base_values = explainer.expected_value\n",
    "lgb_shap = np.load(\"shap_values_LGB.npy\")  # shape: (14535, 42, 12) where 12 is the number of classes\n",
    "\n",
    "# Extract the actual model predictions - this needs to come from your model, not the SHAP values\n",
    "# If you don't have the actual predictions, you can approximate them using the SHAP values:\n",
    "# The sum of SHAP values + base value for each class gives the model output for that class\n",
    "predictions = np.zeros((lgb_shap.shape[0], lgb_shap.shape[2]))\n",
    "for i in range(lgb_shap.shape[2]):  # For each class\n",
    "    # Sum SHAP values across features and add base value\n",
    "    predictions[:, i] = np.sum(lgb_shap[:, :, i], axis=1) + base_values[i]\n",
    "\n",
    "# Apply softmax if needed (if predictions are logits)\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "# Uncomment if predictions are logits and need to be converted to probabilities\n",
    "# predictions = softmax(predictions)\n",
    "\n",
    "# Create the list of SHAP value arrays for each class\n",
    "shap_values_list = [lgb_shap[:, :, i] for i in range(lgb_shap.shape[2])]\n",
    "\n",
    "def class_labels(row_index):\n",
    "    reversed_label_dict = {v: k for k, v in label_dict.items()}\n",
    "    return [f\"{reversed_label_dict[i]} ({predictions[row_index, i]:.2f})\" for i in range(len(reversed_label_dict))]\n",
    "\n",
    "examples = [7000, 219]\n",
    "for row_index in examples:\n",
    "    fig = shap.multioutput_decision_plot(\n",
    "        list(base_values),\n",
    "        shap_values_list,\n",
    "        row_index=row_index,\n",
    "        feature_names=list(feature_names),\n",
    "        highlight=[np.argmax(predictions[row_index])],\n",
    "        legend_labels=class_labels(row_index),\n",
    "        legend_location=\"lower right\",\n",
    "        plot_color=\"tab20\",\n",
    "        show=False\n",
    "    )\n",
    "    # save the plot\n",
    "    plt.savefig(f\"shap_decision_plot_{row_index}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ],
   "id": "3a1f63dcc7a596da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:31:39.876849Z",
     "start_time": "2025-05-28T12:31:39.841855Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_labels = [np.argmax(predictions[row_index]) for row_index in range(predictions.shape[0])]",
   "id": "78b05f94dcef2248",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:33:07.495726Z",
     "start_time": "2025-05-28T12:33:07.478050Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_breast_cancer = [i for i, label in enumerate(predicted_labels) if label == label_dict[\"Breast Carcinoma\"]]",
   "id": "e16800b6527802ec",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e5d95dac6fcebdb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
